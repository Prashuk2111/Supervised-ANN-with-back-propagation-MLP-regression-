{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMjgGiB8ZZuq"
      },
      "outputs": [],
      "source": [
        "# import required packages\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras as keras\n",
        "# make it easier to understand by importing the required libraries within keras\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import initializers\n",
        "from keras.callbacks import EarlyStopping\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UpS_a2NZ5XV"
      },
      "outputs": [],
      "source": [
        "def model(j):\n",
        "    regression_ml_model = keras.models.Sequential([\n",
        "    Dense(j, activation='sigmoid', input_shape=(1,),kernel_initializer=initializers.RandomNormal(stddev=10), bias_initializer=initializers.RandomNormal(stddev=10)),\n",
        "    Dense(1, activation='linear',input_shape=(1,),kernel_initializer=initializers.RandomNormal(stddev=10), bias_initializer=initializers.RandomNormal(stddev=10))\n",
        "          ])\n",
        "    # optimizer = keras.optimizers.Adam(lr=0.0009)\n",
        "    regression_ml_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "    # regression_ml_model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "\n",
        "    return regression_ml_model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzkElFjnhz1p"
      },
      "outputs": [],
      "source": [
        "# from re import VERBOSE\n",
        "# from sklearn.utils import validation\n",
        "\n",
        "def kflod_training(model,X,Y):\n",
        "\n",
        "  if X.size < 10:\n",
        "    Kf_folds = KFold(n_splits=8, shuffle=True)\n",
        "  else:\n",
        "    Kf_folds = KFold(n_splits=10, shuffle=True)\n",
        "\n",
        "  earlystop =EarlyStopping(monitor='val_loss', mode='min',patience = 10)\n",
        "  # earlystop_loss =EarlyStopping(monitor='loss', mode='min',patience = 100)\n",
        "\n",
        "  \n",
        "  train_loss = []\n",
        "  val_loss = []\n",
        "  for training,validation in Kf_folds.split(X, Y):\n",
        "\n",
        "    model_history = model.fit(X[training], Y[training], \n",
        "                            epochs=100,\n",
        "                            validation_data=(X[validation], Y[validation]),\n",
        "                            callbacks=[earlystop],batch_size=1)\n",
        "    \n",
        "    minum_val_loss_index = np.argmin(model_history.history[\"val_loss\"])\n",
        "    train_loss.append(model_history.history[\"loss\"][-1])\n",
        "                      # [minum_val_loss_index])\n",
        "    val_loss.append(model_history.history[\"val_loss\"][-1])\n",
        "                    # [minum_val_loss_index])\n",
        "    \n",
        "\n",
        "  val_loss = np.array(val_loss)\n",
        "  train_loss = np.array(train_loss)\n",
        "\n",
        "  \n",
        "\n",
        "  mean_performance_val_loss = np.mean(val_loss)\n",
        "  mean_performance_loss = np.mean(train_loss)\n",
        "\n",
        "\n",
        "  return model, model_history, mean_performance_val_loss, mean_performance_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "K-oU0zjUbW4v",
        "outputId": "1abc033f-3db4-4f41-ec24-dbc6ec3dd2c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/7 [===>..........................] - ETA: 6s - loss: 3743.5371"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-454ce5f827ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0mmodel_created\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m       \u001b[0mmodel_trained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mkflod_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_created\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m       \u001b[0mmean_val_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0mmean_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-09a86a10b17c>\u001b[0m in \u001b[0;36mkflod_training\u001b[0;34m(model, X, Y)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mKf_folds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     model_history = model.fit(X[training], Y[training], \n\u001b[0m\u001b[1;32m     20\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1692\u001b[0m                             \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m                         )\n\u001b[0;32m-> 1694\u001b[0;31m                     val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1695\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m                         \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2038\u001b[0m                         ):\n\u001b[1;32m   2039\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2040\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2041\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    926\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m     self._concrete_variable_creation_fn = (\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m    \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m         ._get_concrete_function_internal_garbage_collected(\n\u001b[1;32m    751\u001b[0m             *args, **kwds))\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;34m\"\"\"Returns a concrete function which cleans up its graph function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0mconcrete_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_concrete_function_internal_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneralized_func_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_placeholder_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m           \u001b[0mconcrete_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m           \u001b[0mgraph_capture_container\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcrete_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_capture_func_lib\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    281\u001b[0m     ]\n\u001b[1;32m    282\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     concrete_function = monomorphic_function.ConcreteFunction(\n\u001b[0m\u001b[1;32m    284\u001b[0m         func_graph_module.func_graph_from_py_func(\n\u001b[1;32m    285\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func_graph, attrs, shared_func_graph, spec)\u001b[0m\n\u001b[1;32m   1361\u001b[0m     \u001b[0;31m# These each get a reference to the FuncGraph deleter since they use the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m     \u001b[0;31m# FuncGraph directly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m     self._delayed_rewrite_functions = _DelayedRewriteGradientFunctions(\n\u001b[0m\u001b[1;32m   1364\u001b[0m         func_graph, self._attrs, self._garbage_collector)\n\u001b[1;32m   1365\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_order_tape_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func_graph, attrs, func_graph_deleter)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_function_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m     self._inference_function = _EagerDefinedFunction(\n\u001b[0m\u001b[1;32m    464\u001b[0m         \u001b[0m_inference_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         self._func_graph.inputs, self._func_graph.outputs, attrs)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, graph, inputs, outputs, attrs)\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0moutput_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mc_graph\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m       fn = pywrap_tf_session.TF_GraphToFunction_wrapper(\n\u001b[0m\u001b[1;32m    240\u001b[0m           \u001b[0mc_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Datapoints range\n",
        "i = [10,40,80,200]\n",
        "# i = [200,40,80,200]\n",
        "\n",
        "# neurons range \n",
        "j = [2,10,40,100]\n",
        "#j = [100,10,40,100]\n",
        "# np.random.seed(1)\n",
        "\n",
        "models_grid_val_loss = np.zeros((4, 4))\n",
        "models_grid_loss = np.zeros((4, 4))\n",
        "# print(models_grid_loss)\n",
        "\n",
        "for index_i,data_size in enumerate(i):\n",
        "  # x = np.linspace(-1,1,data_size)\n",
        "  x = np.linspace(-2,2,data_size)\n",
        "\n",
        "\n",
        "  # y = x*np.sin((6*np.pi*x))*np.exp((-x**2))\n",
        "  y = np.exp((x**2))*np.arctan(x)*np.sin((4*np.pi*x))\n",
        "\n",
        "  for index_j, neurons in enumerate(j):\n",
        "    \n",
        "    \n",
        "    # shuffling dataset for same model 5 times\n",
        "    mean_val_loss = []\n",
        "    mean_loss = []\n",
        "    for shuffle in range(5):\n",
        "\n",
        "      X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2,shuffle=True)\n",
        "      model_created = model(neurons)\n",
        "      model_trained, model_history, val_loss, loss= kflod_training(model_created,X_train,Y_train)\n",
        "      mean_val_loss.append(val_loss)\n",
        "      mean_loss.append(loss)\n",
        "\n",
        "      # y_pred = model_trained.predict(X_test)\n",
        "\n",
        "      # plt.scatter(x,y, color = \"b\")\n",
        "      # plt.scatter(X_test,y_pred, color = \"g\")\n",
        "  #     break\n",
        "  #   break\n",
        "  # break\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    models_grid_val_loss[index_i][index_j] = mean_val_loss[np.argmin(mean_val_loss)]\n",
        "    models_grid_loss[index_i][index_j] = mean_loss[np.argmin(mean_val_loss)]\n",
        "print(models_grid_val_loss)\n",
        "print(models_grid_loss)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # print(model_history.history.keys())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJwEPBnRREL_",
        "outputId": "1dfdd997-c95f-46c6-8442-5639ed447b02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 5.37743096 18.30296846 81.47357227 11.567099  ]\n",
            " [70.30273875 67.60709114 96.92154443 68.55093472]\n",
            " [89.77311516 74.5639677  84.55175076 79.25005119]\n",
            " [84.66113663 74.94515228 68.22557898 75.7697403 ]]\n",
            "\n",
            "[[  5.23260483  26.45183414 240.95898771   8.02376878]\n",
            " [ 67.72899265  76.45423851  81.37366028  62.05134373]\n",
            " [ 86.98589897  77.27373924  77.03583755  75.32621231]\n",
            " [ 84.00533142  72.37851105  66.81119881  74.46739044]]\n"
          ]
        }
      ],
      "source": [
        "print(models_grid_val_loss)\n",
        "print(\"\")\n",
        "print(models_grid_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aUXXXjgzGO4L",
        "outputId": "ecf48152-0e90-4484-d704-66c163daba81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "160/160 [==============================] - 2s 2ms/step - loss: 269.0739\n",
            "Epoch 2/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 248.3670\n",
            "Epoch 3/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 229.7403\n",
            "Epoch 4/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 212.6543\n",
            "Epoch 5/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 196.9391\n",
            "Epoch 6/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 182.6183\n",
            "Epoch 7/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 169.1045\n",
            "Epoch 8/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 156.6877\n",
            "Epoch 9/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 145.1365\n",
            "Epoch 10/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 134.3709\n",
            "Epoch 11/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 124.1990\n",
            "Epoch 12/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 114.7066\n",
            "Epoch 13/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 105.8090\n",
            "Epoch 14/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 97.4292\n",
            "Epoch 15/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 89.5717\n",
            "Epoch 16/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 82.2303\n",
            "Epoch 17/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 75.4109\n",
            "Epoch 18/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 69.0909\n",
            "Epoch 19/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 63.1612\n",
            "Epoch 20/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 57.6591\n",
            "Epoch 21/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 52.5809\n",
            "Epoch 22/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 48.0197\n",
            "Epoch 23/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 43.7098\n",
            "Epoch 24/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 39.7242\n",
            "Epoch 25/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 36.0646\n",
            "Epoch 26/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 32.6764\n",
            "Epoch 27/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 29.6110\n",
            "Epoch 28/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 26.7944\n",
            "Epoch 29/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 24.2341\n",
            "Epoch 30/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 21.8786\n",
            "Epoch 31/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 19.7308\n",
            "Epoch 32/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 17.7536\n",
            "Epoch 33/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 15.9806\n",
            "Epoch 34/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 14.3657\n",
            "Epoch 35/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 12.9124\n",
            "Epoch 36/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 11.5972\n",
            "Epoch 37/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 10.4022\n",
            "Epoch 38/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 9.3374\n",
            "Epoch 39/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 8.3792\n",
            "Epoch 40/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 7.5234\n",
            "Epoch 41/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 6.7257\n",
            "Epoch 42/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 6.0453\n",
            "Epoch 43/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 5.4160\n",
            "Epoch 44/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 4.8609\n",
            "Epoch 45/500\n",
            "160/160 [==============================] - 1s 5ms/step - loss: 4.3806\n",
            "Epoch 46/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 3.9186\n",
            "Epoch 47/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 3.5191\n",
            "Epoch 48/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 3.1774\n",
            "Epoch 49/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.8423\n",
            "Epoch 50/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.5605\n",
            "Epoch 51/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.3015\n",
            "Epoch 52/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 2.0707\n",
            "Epoch 53/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 1.8766\n",
            "Epoch 54/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 1.6869\n",
            "Epoch 55/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 1.5191\n",
            "Epoch 56/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.3721\n",
            "Epoch 57/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 1.2404\n",
            "Epoch 58/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 1.1207\n",
            "Epoch 59/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 1.0112\n",
            "Epoch 60/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.9187\n",
            "Epoch 61/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.8326\n",
            "Epoch 62/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.7567\n",
            "Epoch 63/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6859\n",
            "Epoch 64/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.6267\n",
            "Epoch 65/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5728\n",
            "Epoch 66/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.5220\n",
            "Epoch 67/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4810\n",
            "Epoch 68/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.4430\n",
            "Epoch 69/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.4076\n",
            "Epoch 70/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3793\n",
            "Epoch 71/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3531\n",
            "Epoch 72/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.3276\n",
            "Epoch 73/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.3084\n",
            "Epoch 74/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2886\n",
            "Epoch 75/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2711\n",
            "Epoch 76/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2552\n",
            "Epoch 77/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2412\n",
            "Epoch 78/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2292\n",
            "Epoch 79/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.2168\n",
            "Epoch 80/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.2075\n",
            "Epoch 81/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1984\n",
            "Epoch 82/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1869\n",
            "Epoch 83/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1826\n",
            "Epoch 84/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1749\n",
            "Epoch 85/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1673\n",
            "Epoch 86/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.1616\n",
            "Epoch 87/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1558\n",
            "Epoch 88/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.1519\n",
            "Epoch 89/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.1476\n",
            "Epoch 90/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.1431\n",
            "Epoch 91/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.1383\n",
            "Epoch 92/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1336\n",
            "Epoch 93/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1299\n",
            "Epoch 94/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1302\n",
            "Epoch 95/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1257\n",
            "Epoch 96/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1224\n",
            "Epoch 97/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1188\n",
            "Epoch 98/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1195\n",
            "Epoch 99/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1166\n",
            "Epoch 100/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1141\n",
            "Epoch 101/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1131\n",
            "Epoch 102/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1125\n",
            "Epoch 103/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1102\n",
            "Epoch 104/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1081\n",
            "Epoch 105/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1064\n",
            "Epoch 106/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1048\n",
            "Epoch 107/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1043\n",
            "Epoch 108/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1039\n",
            "Epoch 109/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1022\n",
            "Epoch 110/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.1007\n",
            "Epoch 111/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0995\n",
            "Epoch 112/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0977\n",
            "Epoch 113/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0971\n",
            "Epoch 114/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0962\n",
            "Epoch 115/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0956\n",
            "Epoch 116/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0937\n",
            "Epoch 117/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0950\n",
            "Epoch 118/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0950\n",
            "Epoch 119/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0922\n",
            "Epoch 120/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0910\n",
            "Epoch 121/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0897\n",
            "Epoch 122/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0892\n",
            "Epoch 123/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0888\n",
            "Epoch 124/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0883\n",
            "Epoch 125/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0872\n",
            "Epoch 126/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0873\n",
            "Epoch 127/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0865\n",
            "Epoch 128/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0847\n",
            "Epoch 129/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0853\n",
            "Epoch 130/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0850\n",
            "Epoch 131/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0837\n",
            "Epoch 132/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0826\n",
            "Epoch 133/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0823\n",
            "Epoch 134/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0814\n",
            "Epoch 135/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0814\n",
            "Epoch 136/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0814\n",
            "Epoch 137/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0797\n",
            "Epoch 138/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0805\n",
            "Epoch 139/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0802\n",
            "Epoch 140/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0799\n",
            "Epoch 141/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0779\n",
            "Epoch 142/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0776\n",
            "Epoch 143/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0777\n",
            "Epoch 144/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0776\n",
            "Epoch 145/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0753\n",
            "Epoch 146/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0758\n",
            "Epoch 147/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0766\n",
            "Epoch 148/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0758\n",
            "Epoch 149/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0760\n",
            "Epoch 150/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0739\n",
            "Epoch 151/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0746\n",
            "Epoch 152/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0745\n",
            "Epoch 153/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0735\n",
            "Epoch 154/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0745\n",
            "Epoch 155/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0745\n",
            "Epoch 156/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0725\n",
            "Epoch 157/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0729\n",
            "Epoch 158/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0728\n",
            "Epoch 159/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0720\n",
            "Epoch 160/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0733\n",
            "Epoch 161/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0707\n",
            "Epoch 162/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0716\n",
            "Epoch 163/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0716\n",
            "Epoch 164/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0703\n",
            "Epoch 165/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0707\n",
            "Epoch 166/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0704\n",
            "Epoch 167/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0706\n",
            "Epoch 168/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0700\n",
            "Epoch 169/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0702\n",
            "Epoch 170/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0705\n",
            "Epoch 171/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0700\n",
            "Epoch 172/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0687\n",
            "Epoch 173/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0705\n",
            "Epoch 174/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0695\n",
            "Epoch 175/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0687\n",
            "Epoch 176/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0692\n",
            "Epoch 177/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0680\n",
            "Epoch 178/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0669\n",
            "Epoch 179/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0715\n",
            "Epoch 180/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0685\n",
            "Epoch 181/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0694\n",
            "Epoch 182/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0680\n",
            "Epoch 183/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0674\n",
            "Epoch 184/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0668\n",
            "Epoch 185/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0678\n",
            "Epoch 186/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0677\n",
            "Epoch 187/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0673\n",
            "Epoch 188/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0672\n",
            "Epoch 189/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0666\n",
            "Epoch 190/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0665\n",
            "Epoch 191/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0663\n",
            "Epoch 192/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0667\n",
            "Epoch 193/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0673\n",
            "Epoch 194/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0665\n",
            "Epoch 195/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0663\n",
            "Epoch 196/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0665\n",
            "Epoch 197/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0665\n",
            "Epoch 198/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0657\n",
            "Epoch 199/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0669\n",
            "Epoch 200/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0656\n",
            "Epoch 201/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0660\n",
            "Epoch 202/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0664\n",
            "Epoch 203/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0661\n",
            "Epoch 204/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0649\n",
            "Epoch 205/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0657\n",
            "Epoch 206/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0658\n",
            "Epoch 207/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0644\n",
            "Epoch 208/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0644\n",
            "Epoch 209/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0655\n",
            "Epoch 210/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0656\n",
            "Epoch 211/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0651\n",
            "Epoch 212/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0647\n",
            "Epoch 213/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0653\n",
            "Epoch 214/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0649\n",
            "Epoch 215/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0640\n",
            "Epoch 216/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0641\n",
            "Epoch 217/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0644\n",
            "Epoch 218/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0639\n",
            "Epoch 219/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0647\n",
            "Epoch 220/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0636\n",
            "Epoch 221/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0642\n",
            "Epoch 222/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0643\n",
            "Epoch 223/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0639\n",
            "Epoch 224/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0660\n",
            "Epoch 225/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0644\n",
            "Epoch 226/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0649\n",
            "Epoch 227/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0658\n",
            "Epoch 228/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0632\n",
            "Epoch 229/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0633\n",
            "Epoch 230/500\n",
            "160/160 [==============================] - 1s 4ms/step - loss: 0.0629\n",
            "Epoch 231/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0632\n",
            "Epoch 232/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0642\n",
            "Epoch 233/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0641\n",
            "Epoch 234/500\n",
            "160/160 [==============================] - 1s 3ms/step - loss: 0.0633\n",
            "Epoch 235/500\n",
            "160/160 [==============================] - 0s 3ms/step - loss: 0.0637\n",
            "Epoch 236/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0637\n",
            "Epoch 237/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0629\n",
            "Epoch 238/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0634\n",
            "Epoch 239/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0632\n",
            "Epoch 240/500\n",
            "160/160 [==============================] - 0s 2ms/step - loss: 0.0640\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 19 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f377c307ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss'])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAeIElEQVR4nO3dfZAc9X3n8fd3pRXWFvaCVipQgJ2BipKYWC6w9jjHKR+xRWLMFQ9xfI5cQyI/UBtCcgWV8+VwbdUZkdoLwZdYpGIf2eNMZO1UjENMEGVTRAi4pHLgY6kAG0xhyUQrwwmQZKM7SoQH6Xt/dI/o3e157J6Znu7Pq2pqph+m+7f98N3f/J7a3B0REcm/oX4nQEREekMBX0SkIBTwRUQKQgFfRKQgFPBFRApiZb8TUM/atWu9XC73OxkiIgPliSeeOOzu6+KWZTbgl8tl5ubm+p0MEZGBYmYL9ZapSEdEpCAU8EVECkIBX0SkIBTwRUQKQgFfRKQgFPB7pFqFchmGhoL3arXfKRIprqLej5ltlpkn1SpMTsKxY8H0wkIwDVCp9C9dIkVU5PvRsjo88sTEhOelHX65HFxUS5VKsH9/r1MjUmx5vx/N7Al3n4hbpiKdHjhwoL35ItI9Rb4fUwn4ZnapmT1nZvvM7MYG6/2ambmZxf73yavx8fbmi0j3FPl+TBzwzWwF8FXg48D5wKfN7PyY9d4NXA98L+k+B830NIyMLJ43MhLMF5HeqFXULiyA2eJlRbkf08jhXwTsc/fn3f1N4JvAlTHr/QHwR8C/pLDPgVKpwMxMUEZoFrzPzOS/gkgkK2oVtbWye/d3gn6R7sc0WumcBfwoMv0C8K+jK5jZB4Bz3P07ZvYfU9jnwKlUinFBiWTR1NQ7rXJq3PNTUduqrlfamtkQ8CfAf2hh3UkzmzOzuUOHDnU7aSJSEEWuqI1KI+C/CJwTmT47nFfzbuB9wCNmth/4ILArruLW3WfcfcLdJ9atix3OWUSkbUWuqI1KI+A/Dmwws3PNbBWwBdhVW+juR919rbuX3b0MPAZc4e75aGQvIpmnhhOBxAHf3d8Gfhd4AHgW+Ja7P2NmN5vZFUm3LyKSlBpOBNTTVkQkR9TTVkREFPBFRIpCAV+aKupQsiJ5o+GRpaEiDyUrkjfK4UtDcT0Ujx0L5ovIYFHAl4bUQ1EkPxTwpSH1UBTJDwV8aUg9FEXyQwFfGlIPRZH8UCsdaUpDO4vkg3L4kpja6YsMBuXwJRG10xcZHMrhSyJqpy8yOBTwJRG10xcZHAr4koja6Uve5LlOSgFfElE7fcmTWp3UwkLwkPNanVRegr4CfkYMaq5C7fQlizq9n/JeJ6UnXmXA0pYuEOSSFThF2pfkfhoaCnL2S5nBiRPpprNbGj3xSgE/A8rl4KfjUqUS7N/f69SIDLYk91Me7kU94jDj1NJFJD1J7qe810kp4GeAWrqIpCfJ/ZT3OikF/AzIe65CpJeS3k+VSlB8c+JE8J6XYA8K+JmQ91yFSC/pfqovlUpbM7sUuA1YAdzh7rcsWf57wDXA28Ah4HPuHlM18o4iVdqKiKSlq5W2ZrYC+CrwceB84NNmdv6S1f4RmHD39wN3A7cm3a+IiLQnjSKdi4B97v68u78JfBO4MrqCuz/s7rVWsY8BZ6ewXxERaUMaAf8s4EeR6RfCefV8Hrg/boGZTZrZnJnNHTp0KIWkiYhITU8rbc3samAC+HLccnefcfcJd59Yt25dL5MmIjkxqMOU9EIaD0B5ETgnMn12OG8RM7sEmAIudvc3UtiviMgieiBPY2nk8B8HNpjZuWa2CtgC7IquYGYXAn8OXOHur6SwTxGRZfI++FlSiQO+u78N/C7wAPAs8C13f8bMbjazK8LVvgycCvyVmT1pZrvqbC7TqvNVytvLDG0bory9THVevxVFskTDlDSWyjNt3f27wHeXzPvPkc+XpLGffqrOV5m8b5JjbwXZh4WjC0zeF/xWrGzUb0WRLBgfjx/8TMOUBNTTtkVTe6ZOBvuaY28dY2qPfiuKZIWGKWlMAb9FB47G/yasN19Eek/DKjSWSpFOEYyPjrNwdPlvxfFR/VYUyZJKRQG+HuXwWzS9eZqR4cW/FUeGR5jerN+KIjIYFPBbVNlYYebyGUqjJQyjNFpi5vIZVdiKyMDQIw5FRBqoVoN2/AcOBK19pqezXWTUaLRMleGLiNSRt567KtIRkVzoxhg6eeu5q4AvIqnr9QBmtZz4wgK4v5MTT7rfvPXcVcAXkVR1K/g20q2ceJIHomeRAr4UWlaG0q2N02TbjJU3r8S22cCO19SPYpBu5cTz1nNXAV8Kqx850dh0hOM01Tr2HffjwDvjNQ1a0O9HMUi3cuJ567mrgC+FVS8nunVrb4N+3DhNJ9MzgOM19aMYpJs58UoF9u+HEyeC90EN9qCALwVWL8d5/HjrOf00hsxuNh7ToI3X1I9ikLzlxLtFHa+ksMrl+KF0a0qlIEcHQWCf2jPFgaMHWLN6DQBHXj+CYTjv3EMjwyNt98BeO13myNv1E1IaLbH/hv0tby8LBq2zUp406nilHL4UVlxONOrAgSDQr711LVd/+2oWji7gOEdeP8KR148ALAr20GERzIPT8GZ8QgZ1vKY8FYPkiXraSmFVKvAP/7fKf/vBFIwuwIkVMHQcjpZgzzRrxlj00JtWtVsE8+P/WYEjwObl6Zj53LTGa5LUKOBLYVXnq+z4ySScFgb0FUHrGE5bgCsmeeOU1W0He2h/yOzxcViYr8D84sC+YgUwAWxsOwmSsrwUUalIRwqrUesYho/x2okjbW+zkyKYekVL7VQeS/dkpfluGhTwpbDSav1iGEDHQ2bXWpisWLF82SCP25IXeRpPRwE/o7LSAzTPmhW9jK0eY5Utz3qfuupUxlaPYRhjK0useWQnts1h+354urPf+ZVKUMEZZ1DHbemlbt4veRpPRwE/g/L0EzLL4p5iVjMyPMKn3n0bvmsGXi2BW/D+17Oc8sf/j9vOOszOnz7B6/9lP0ceqaRynvI2bkuvdPt+ydV5cffEL+BS4DlgH3BjzPJTgLvC5d8Dys22uWnTJu/E7Kx7qeRuFrzPzna0mdTNPj3rpa+U3G4yL32l5LNP109YqeQeXLqLX6VSz5JbGLXzwk34im0rnJs4eX7qnQcIrq96yzo9T7Oz7iMji7c1MpKda7gd7VzvSXX7funleUkjfgFzXi9W11vQ6gtYAfwQOA9YBTwFnL9kneuA28PPW4C7mm23k4Cf1Rtm9ulZH5kecW7i5GtkeqTuTVAvmJj1OOF91MuAUU+joN7oleQ8ZTXD0o52r/ekenG/9OK8zM66D2+adW4oOV8y54aSD2+abXtfjQJ+4p62ZvYLwE3u/rFw+ovhL4c/jKzzQLjOo2a2EngJWOcNdt5JT9t6PSejPSb7oby9fHJgrKh6PSiz+nf0Sm0wsWgLmk56sCbVrCduPUU5T/W0e70n3l85H/fL2o9UOfKhSVgVqSF+c4Sx/zXD4Ydbv+673dP2LOBHkekXwnmx67j728BRYCwmoZNmNmdmc4cOHWo7IVmtXKnXGqTe/LwNydpI3Fg0cc0l+zGIWLOeuHHyep7a0e71nlRe7pcjF0wtDvYAq44F81OSqUpbd59x9wl3n1i3bl3b389q5Uq91iD15hdlIKjosMCOnxwOOC53CL0fRKx2HsaWZU3i5fU8tavd6z2pQb1flmZ2GK3zc3I0ves+jYD/InBOZPrscF7sOmGRzihBZ/JUZfU/fVxrkGYddPI2Fkk7OfkVFtMgne4FjEYqFTh8GGZng0ACQVCJGhkJlufhPKWhk+s9qUG7X677znX8xrd/Y1FmZ9mFFRobTu+6TyPgPw5sMLNzzWwVQaXsriXr7AK2hp8/CTzUqPy+U1n9T1/ZWGHm8hlKoyUM67iDzqCqzlf53D2Lc/K16TjH/XjPA0YztYDiDjt3Zu8ay5KiX+/NVOer3D53+7KB98CBxUF/lY1w2xXpXfepDI9sZpcB2wla7Hzd3afN7GaC2uJdZvYuYCdwIfBjYIu7P99omxoeOT/qDf87xApOcHzZ/NJoienN0yeHIx4fHWd6swYRk/5LMqZO7VdtvYxOTWm0lOi6b1Rpq/HwpevspiGwmOvMYWTVSN9b44i0otbBKzrMwshI41940SC/9NkJcdJoyaTx8KWrmj716WidMsijJf30l4HR7pg6S59V3CzYG9b1Ykvl8CWRVtrMp9W+WKSfhoaCOpylzOLHQarXHyGOYVw7cS1f+7dfS5hK5fCli1ppM3/bNRWGH1g8Js3wAzPcdo2CvQyOdpt9t9qMuDRaYucndqYS7JvRA1AkkVY62QTlmxWmpioD/wAJKa7p6fgy/HrNvsdHxxvm8PtRX6UcfkY0LQfvo0Zpa7WTzaC1kxZZKq7Z99b/WmXqUPy9EdcfIemzE5JSwM+Aej1OsxD0m6WtH51sRPolmnGZvi94RGa9eyOuP8LOT+zEv+Tsv2F/XxonFLbSttZcKgvtvHs92FQ7Wklblo6lSDdFr/UhG+K4x/cj6ed926jStpBl+EtbltT+MwN9CVS9HmyqHS2V0W+sKMBLblXnq1x///UceX3xaDBxwR6ycd/WU8ginayMxljT68Gm2pHltIl0W3W+ymf/5rPLgn0jWb43Chnws5ajjisHHx4a5rU3X+t7Ja7K6KVooo0Utt6zlbdOvNXyd7N+bxQy4Heaa+3Wg5KXVu6MrR7DzDjy+pG+V+JqICwpkqWNFOoV20StsBUDc28UstK2kycqdTKORqeyXIkrkmft9I6FbI79pJ62S3SSa213HI0kulHklOV2/iK9Vu9+aOceG1s9lrlg30whW+lA+y1Levn4xHo99KJFTu00hcxaqySRfqg3cmX0fqh370XXH1s9xm0fv20g751C5vA70cvHJzarKG23o1bWWiWJ9FqzkStr90O9e6/WYcq/5Bz+/cMDGexBAb9lvXx8YrMip3YDeNZaJYl0U3W+ytpb12LbDNtmrL11Ldfff/2ye2apA0cP5L6RQmGLdNpVq5jt9Gk3be+vQZFTuwG8lSIikUFWr3MU0HIb+tr9kOeOhMrhtyErA4C126xUbell0DVqdNBJ56ilinI/KOAPoHYDeN5/pkq+Nauzmtoz1VbnqJp+j1zZD4Vsh58HGrBMiqJZv5ShbUNNHx8IQeuaU1edmvt7RoOn5VCeyxlFoprVWTV70AgEQ5UMalPKNKlIR0QyrVmd1fTmaYaHhut+f2z1GHdedWfhgz0kDPhmtsbMdpvZ3vD99Jh1LjCzR83sGTN72sx+Pck+RaRYmtVZVTZWuPOqOxlbPXZy+djqMWY/MTvw7ebTljSHfyOwx903AHvC6aWOAb/p7j8PXApsN7PTEu63Zd0a8EzSofMjzbTS6KCyscLh3z88UJ2j+nLtu3vHL+A5YH34eT3wXAvfeQrY0Gy9TZs2eVKzs+4jI+7wzmtkJJgv/afzI0XVzWsfmPM6cTVRKx0ze9XdTws/G/CT2nSd9S8CdgA/7+4nYpZPApMA4+PjmxYWWh+1Lk65DHGbKJWCdvTSXzo/UlTdvPYbtdJpGvDN7EHgzJhFU8COaIA3s5+4+7Jy/HDZeuARYKu7P9Ys0Wk0yxwaCv53Lk9L0HlK+kvnR4qqm9d+ouGR3f0Sd39fzOte4OUwkNcC+it1EvAe4DvAVCvBPi29HPBM2tfo/KhsX/KsX7EpaaXtLmBr+HkrcO/SFcxsFXAP8A13vzvh/trSywHPpH31zs9llwUPm1lYCHJBCwvBtIK+5EXfYlO9wv1WXsAYQeucvcCDwJpw/gRwR/j5auAt4MnI64Jm206j0tY9qAQpldzNgndVCGZL3PkplRZXZtVepVJ/0yqSpm7FJrpVadtNGlqhuFS2L9I5PeJQBorqXmRQDFpdkwJ+QQzSham6FxkE1WrndU19ux/rlfX0+5VWGb4MZgcn1b1I1nVa19Tt+xGV4RebOjiJpK/TuqZu348qwy+4A3UeXVtvvog012ldUz/vRwX8AlAlqEj6Oq1r6uf9qIBfAKoEFUlfpQIzM0FRjFnwPjPT/FnX/bwfFfALoNMLU0Qaq1SCcvcTJ4L3Vu6pft6PqrQVEckRVdqKiIgCvohIUSjgi4gUhAL+gBqkoRJEktL1no6V/U6AtK82hsexY8F0bQwPUMsbyR9d7+lRK50BpKESpEh0vbdHrXRyRkMlSJHk5XrPQrGUAv4A0lAJUiR5uN6TDKWcJgX8AaShEqRI8nC9T029UwdRc+xYML+XFPAHkIZKkCLJw/WelWIpVdqKiHRZLyueVWkbIwsVKCJSDFkplipkwM9KBYqIFENWiqUSBXwzW2Nmu81sb/h+eoN132NmL5jZnyXZZxqyUoEiIvkWLUmYmgpy9O0MpZy2pDn8G4E97r4B2BNO1/MHwN8l3F8qslKBIiL5lcWShKQB/0pgR/h5B3BV3Epmtgk4A/jbhPtLRR7a9YpItmWxJCFpwD/D3Q+Gn18iCOqLmNkQ8MfAFxLuKzVZqUARkfzKYklC08HTzOxB4MyYRYv+T7m7m1lcG8/rgO+6+wtm1mxfk8AkwHgXs9u1srOpqeDgj48HwX6Q2vWKSLaNj8c3xexnSUKidvhm9hzwS+5+0MzWA4+4+88uWacKfBg4AZwKrAK+5u6NyvvVDl9EBtrSUT4hKEnoduucbrbD3wVsDT9vBe5duoK7V9x93N3LBMU632gW7EVEBl1WmmJGJR0P/xbgW2b2eWAB+BSAmU0A17r7NQm3LyIysCqVbBUVa2gFEZEcKfTQCtX5KuXtZYa2DVHeXqY6r+60IlJMuX7EYXW+yuR9kxx7K6g1WTi6wOR9wbPRKhsz9DtLRKQHcp3Dn9ozdTLY1xx76xhTezSGgogUT64D/oGj8T0c6s0XEcmzXAf88dH4Hg715ouI5FmuA/705mlGhhePoTAyPML0Zo2hICLFk+uAX9lYYebyGUqjJQyjNFpi5vIZVdiKSCGpHb6ISI4Uuh2+iIgEFPBFRApCAV9EpCAU8EVECkIBX0SkIBTwRUQKQgFfRKQgFPBFRApCAV9EpCAU8EVECkIBX0SkIBTwRUQKQgFfRKQgFPBFRApCAV9EpCASBXwzW2Nmu81sb/h+ep31xs3sb83sWTP7vpmVk+xXRETalzSHfyOwx903AHvC6TjfAL7s7u8FLgJeSbhfERFpU9KAfyWwI/y8A7hq6Qpmdj6w0t13A7j7a+5+LOF+RUSkTUkD/hnufjD8/BJwRsw6PwO8ambfNrN/NLMvm9mKuI2Z2aSZzZnZ3KFDhxImTUREolY2W8HMHgTOjFk0FZ1wdzezuAfkrgQ+DFwIHADuAj4D/I+lK7r7DDADwTNtm6VNRERa1zTgu/sl9ZaZ2ctmtt7dD5rZeuLL5l8AnnT358Pv/A3wQWICvoiIdE/SIp1dwNbw81bg3ph1HgdOM7N14fRHge8n3K+IiLQpacC/BfhlM9sLXBJOY2YTZnYHgLsfB74A7DGzecCA/55wvyIi0qamRTqNuPsRYHPM/Dngmsj0buD9SfYlIiLJqKetiEhBKOCLiBSEAr6ISEEo4IuIFIQCvohIQSjgi4gUhAK+iEhBKOCLiBSEAr6ISEEo4IuIFIQCvohIQSjgi4gUhAK+iEhBKOCLiBSEAr6ISEEo4IuIFIQCvohIQSjgi4gUhAK+iEhBKOCLiBSEAr6ISEEo4IuIFESigG9ma8xst5ntDd9Pr7PerWb2jJk9a2Z/amaWZL8iItK+pDn8G4E97r4B2BNOL2JmHwJ+EXg/8D7gXwEXJ9yviIi0KWnAvxLYEX7eAVwVs44D7wJWAacAw8DLCfcrIiJtShrwz3D3g+Hnl4Azlq7g7o8CDwMHw9cD7v5s3MbMbNLM5sxs7tChQwmTJiIiUSubrWBmDwJnxiyaik64u5uZx3z/p4H3AmeHs3ab2Yfd/e+XruvuM8AMwMTExLJtiYhI55oGfHe/pN4yM3vZzNa7+0EzWw+8ErParwKPuftr4XfuB34BWBbwRUSke5IW6ewCtoaftwL3xqxzALjYzFaa2TBBhW1skU4aqvNVytvLDG0bory9THW+2q1diYgMlKQB/xbgl81sL3BJOI2ZTZjZHeE6dwM/BOaBp4Cn3P2+hPuNVZ2vMnnfJAtHF3CchaMLTN43qaAvIgKYezaLyicmJnxubq6t75S3l1k4urBsfmm0xP4b9qeUMhGR7DKzJ9x9Im5ZrnraHjh6oK35IiJFkquAPz463tZ8EZEiyVXAn948zcjwyKJ5I8MjTG+e7lOKRESyI1cBv7KxwszlM5RGSxhGabTEzOUzVDZW+p00EZG+y1WlrYhI0RWm0lZEROpTwBcRKQgFfBGRglDAFxEpCAV8EZGCyGwrHTM7BCwfJ6F1a4HDKSUnTUpXe5Su9ihd7cljukruvi5uQWYDflJmNlevaVI/KV3tUbrao3S1p2jpUpGOiEhBKOCLiBREngP+TL8TUIfS1R6lqz1KV3sKla7cluGLiMhiec7hi4hIhAK+iEhBDHTAN7N/Z2bPmNkJM6vbhMnMLjWz58xsn5ndGJl/rpl9L5x/l5mtSilda8xst5ntDd9Pj1nnI2b2ZOT1L2Z2VbjsL8zsnyPLLuhVusL1jkf2vSsyv5/H6wIzezQ830+b2a9HlqV2vOpdK5Hlp4R/+77wWJQjy74Yzn/OzD7WaRo6TNfvmdn3w2Ozx8xKkWWx57OHafuMmR2KpOGayLKt4Xnfa2Zbe5imr0TS8wMzezWyrGvHy8y+bmavmNk/1VluZvanYbqfNrMPRJYlP1buPrAv4L3AzwKPABN11llB8BD184BVBA9SPz9c9i1gS/j5duC3U0rXrcCN4ecbgT9qsv4a4MfASDj9F8Anu3C8WkoX8Fqd+X07XsDPABvCzz8FHAROS/N4NbpWIutcB9weft4C3BV+Pj9c/xTg3HA7K1I6Pq2k6yOR6+e3a+lqdD57mLbPAH8W8901wPPh++nh59N7kaYl6/974Os9Ol7/BvgA8E91ll8G3A8Y8EHge2keq4HO4bv7s+7+XJPVLgL2ufvz7v4m8E3gSjMz4KPA3eF6O4CrUkraleH2Wt3uJ4H73f1YSvuvp910ndTv4+XuP3D3veHn/wO8AsT2Jkwg9lppkNa7gc3hsbkS+Ka7v+Hu/wzsC7fXk3S5+8OR6+cx4OyU9p04bQ18DNjt7j92958Au4FL+5CmTwN/mcJ+m3L3vyPI3NVzJfANDzwGnGZm60npWA10wG/RWcCPItMvhPPGgFfd/e0l89NwhrsfDD+/BJzRZP0tLL/gpsOfdF8xs1N6nK53mdmcmT1WK2YiQ8fLzC4iyLn9MDI7jeNV71qJXSc8FkcJjk0r3+1Uu9v+PEEusSbufKal1bT9Wnh+7jazc9r8brfSRFj0dS7wUGR2N49XM/XSnsqxWpkoaT1gZg8CZ8YsmnL3e3udnppG6YpOuLubWd22r+F/743AA5HZXyQIfKsI2uP+J+DmHqar5O4vmtl5wENmNk8Q2DqW8vHaCWx19xPh7I6PV96Y2dXABHBxZPay8+nuP4zfQlfcB/ylu79hZr9F8Avpoz3cfyNbgLvd/XhkXr+PV9dkPuC7+yUJN/EicE5k+uxw3hGCn0srw5xabX7idJnZy2a23t0PhgHqlQab+hRwj7u/Fdl2Lbf7hpndCXyhl+ly9xfD9+fN7BHgQuCv6fPxMrP3AN8h+Gf/WGTbHR+vJepdK3HrvGBmK4FRgmuple92qqVtm9klBP9AL3b3N2rz65zPtAJY07S5+5HI5B0EdTa17/7Sku8+0os0RWwBfic6o8vHq5l6aU/lWBWhSOdxYIMFLUxWEZzgXR7UhDxMUH4OsBVI6xfDrnB7rWx3WflhGPRq5eZXAbE1+t1Il5mdXisSMbO1wC8C3+/38QrP3T0E5Zt3L1mW1vGKvVYapPWTwEPhsdkFbLGgFc+5wAbgf3eYjrbTZWYXAn8OXOHur0Tmx57PlNLVatrWRyavAJ4NPz8A/EqYxtOBX2HxL92upSlM188RVIA+GpnX7ePVzC7gN8PWOh8EjoYZmnSOVbdqo3vxAn6VoCzrDeBl4IFw/k8B342sdxnwA4L/0lOR+ecR3JT7gL8CTkkpXWPAHmAv8CCwJpw/AdwRWa9M8J97aMn3HwLmCQLXLHBqr9IFfCjc91Ph++ezcLyAq4G3gCcjrwvSPl5x1wpB8dAV4ed3hX/7vvBYnBf57lT4veeAj6d8rTdL14PhPVA7Nruanc8epu0PgWfCNDwM/Fzku58Lj+U+4LO9SlM4fRNwy5LvdfV4EWTuDobX8gsE9S3XAteGyw34apjueSKtD9M4VhpaQUSkIIpQpCMiIijgi4gUhgK+iEhBKOCLiBSEAr6ISEEo4IuIFIQCvohIQfx/UdUK89zgvF8AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# i = 80\n",
        "i = 200\n",
        "j = 10\n",
        "# j = 40\n",
        "\n",
        "\n",
        "\n",
        "x = np.linspace(-1,1,i)\n",
        "# x = np.linspace(-2,2,i)\n",
        "\n",
        "\n",
        "y = x*np.sin((6*np.pi*x))*np.exp((-x**2))\n",
        "# y = np.exp((x**2))*np.arctan(x)*np.sin((4*np.pi*x))\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2,shuffle=True)\n",
        "model_created = model(j)\n",
        "earlystop =EarlyStopping(monitor='loss', mode='min', patience = 10)\n",
        "model_history = model_created.fit(X_train, Y_train, \n",
        "                            epochs=500,batch_size=1,callbacks=[earlystop])\n",
        "\n",
        "Y_pred = model_created.predict(X_test)\n",
        "\n",
        "plt.scatter(X_test,Y_test, color = \"b\")\n",
        "plt.scatter(X_test,Y_pred, color = \"g\")\n",
        "\n",
        "\n",
        "model_history.history.keys()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "LXYRgt9N0-w8",
        "outputId": "d2becfd9-1899-40c2-e753-0730586ed1d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f377c181d30>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.scatter(x,y, color = \"b\")\n",
        "plt.scatter(x,model_created.predict(x),color = \"g\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}